---
# 0) Prereqs: make sure yq (Go binary) and yamllint are available
- name: Ensure yq v4 and yamllint are installed
  apt:
    name:
      - curl        # to fetch yq
      - yamllint
    state: present
    update_cache: yes
  become: true

- name: Download Mike Farah’s yq v4 if not present
  get_url:
    url: https://github.com/mikefarah/yq/releases/download/v4.30.8/yq_linux_amd64
    dest: /usr/local/bin/yq
    mode: '0755'
  become: true

# 1) Make sure our audit log dir & policy file exist
- name: Create audit log directory
  file:
    path: /var/log/kubernetes/audit
    state: directory
    mode: '0700'
  become: true

- name: Copy audit policy to control-plane
  copy:
    src: k8s-metrics-data/audit-policy.yaml
    dest: /etc/kubernetes/audit-policy.yaml
    owner: root
    group: root
    mode: '0644'
  become: true

# 2) Ensure the manifest begins with a YAML document start
- name: Ensure '---' at top of kube-apiserver manifest
  lineinfile:
    path: /etc/kubernetes/manifests/kube-apiserver.yaml
    line: '---'
    insertafter: BOF
    state: present
  become: true

# 3) Clean out *any* existing audit mounts/volumes so we start idempotent
- name: Remove existing audit-policy mount
  command: >
    yq eval -i '
      with(.spec.containers[] | select(.name=="kube-apiserver");
        .volumeMounts |= map(select(.name!="audit-policy"))
      )
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  ignore_errors: true
  become: true

- name: Remove existing audit-logs mount
  command: >
    yq eval -i '
      with(.spec.containers[] | select(.name=="kube-apiserver");
        .volumeMounts |= map(select(.name!="audit-logs"))
      )
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  ignore_errors: true
  become: true

- name: Remove existing audit-policy volume
  command: >
    yq eval -i '
      .spec.volumes |= map(select(.name!="audit-policy"))
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  ignore_errors: true
  become: true

- name: Remove existing audit-logs volume
  command: >
    yq eval -i '
      .spec.volumes |= map(select(.name!="audit-logs"))
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  ignore_errors: true
  become: true

- name: Remove any existing audit mounts
  command: >
    yq eval -i '
      with(.spec.containers[] | select(.name=="kube-apiserver");
        .volumeMounts |= (unique_by(.name))
      )
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true

- name: Ensure audit log file exists
  file:
    path: /var/log/kubernetes/audit/audit.log
    state: touch
    owner: root
    group: root
    mode: '0640'
  become: true

- name: Add --audit-log-path and --audit-policy-file to kube-apiserver args
  command: >
    yq eval -i '
      (.spec.containers[] | select(.name=="kube-apiserver") .command)
        += ["--audit-log-path=/var/log/kubernetes/audit/audit.log",
            "--audit-policy-file=/etc/kubernetes/audit-policy.yaml"]
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true
  notify: Restart kubelet

# 4) Insert the four audit blocks structurally via yq
- name: Add audit-policy mount to kube-apiserver
  command: >
    yq eval -i '
      (.spec.containers[] | select(.name=="kube-apiserver") .volumeMounts) +=
      [{"name":"audit-policy",
        "mountPath":"/etc/kubernetes/audit-policy.yaml",
        "readOnly":true}]
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true
  notify: Restart kubelet

- name: Add audit-logs mount to kube-apiserver
  command: >
    yq eval -i '
      (.spec.containers[] | select(.name=="kube-apiserver") .volumeMounts) +=
      [{"name":"audit-logs",
        "mountPath":"/var/log/kubernetes/audit",
        "readOnly":false}]
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true
  notify: Restart kubelet

- name: Add audit-policy volume to kube-apiserver
  command: >
    yq eval -i '
      .spec.volumes +=
      [{"name":"audit-policy",
        "hostPath":{"path":"/etc/kubernetes/audit-policy.yaml","type":"FileOrCreate"}}]
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true
  notify: Restart kubelet

- name: Add audit-logs volume to kube-apiserver
  command: >
    yq eval -i '
      .spec.volumes +=
      [{"name":"audit-logs",
        "hostPath":{"path":"/var/log/kubernetes/audit","type":"DirectoryOrCreate"}}]
    ' /etc/kubernetes/manifests/kube-apiserver.yaml
  become: true
  notify: Restart kubelet

# 5) Lint the resulting manifest (80-char rule disabled)
- name: Lint kube-apiserver manifest (ignore line-length)
  command: >
    yamllint
      -d "{extends: default, rules: {line-length: disable}}"
      --strict --format parsable
      /etc/kubernetes/manifests/kube-apiserver.yaml
  register: lint_result
  failed_when: lint_result.rc != 0
  changed_when: false
  become: true

# 6) If lint passed, restart kubelet so API server picks up the new manifest
- name: Restart kubelet to apply new kube-apiserver manifest
  service:
    name: kubelet
    state: restarted
  become: true

#######################################################################
# Jenkins → Kubernetes service-account + kubeconfig                    #
#######################################################################
# 0. Ensure Python3 and pip exist (dist-agnostic)
- name: Install python3 & pip on master
  become: true
  package:
    name:
      - python3                 # present on most images, but explicit is safe
      - python3-pip             # Ubuntu/Debian
  when:
    - "'master-node' in group_names"
    - ansible_pkg_mgr == "apt"

- name: Install python3 & pip on master (Yum/RHEL/Amazon Linux)
  become: true
  package:
    name:
      - python3
      - python3-pip
  when:
    - "'master-node' in group_names"
    - ansible_pkg_mgr == "yum"

- name: Install Kubernetes Python client (pip3)
  become: true
  pip:
    name: kubernetes==27.2.0         
    executable: pip3                  
  when: "'master-node' in group_names"

# --- 1. make sure the SA exists ---------------------------------
- name: Ensure jenkins-agent service-account
  kubernetes.core.k8s:
    api_version: v1
    kind: ServiceAccount
    name: jenkins-agent
    namespace: default
    state: present
  environment:
    KUBECONFIG: "{{ ansible_env.HOME }}/.kube/config"

# --- 2. bind it to cluster-admin (wide-open but simple) ---------
- name: Create 24-hour token for Jenkins agent
  command: kubectl create token jenkins-agent --duration=24h
  register: jenkins_token_cmd
  become: true
  environment:
    KUBECONFIG: /etc/kubernetes/admin.conf
  when: "'master-node' in group_names"

- name: Read cluster CA (base64 already)
  slurp:
    src: /etc/kubernetes/pki/ca.crt
  register: k8s_ca
  become: true
  when: "'master-node' in group_names"

- name: Set facts for kube-config
  set_fact:
    jenkins_token: "{{ jenkins_token_cmd.stdout }}"
    jenkins_ca_b64: "{{ k8s_ca.content }}"
  no_log: true
  when: "'master-node' in group_names"

# --- 3. Write minimal kube-config on the control host ------------------
- name: Write kubeconfig for Jenkins
  copy:
    dest: "{{ playbook_dir }}/jenkins-kubeconfig.yaml"
    mode: '0600'
    content: |
      apiVersion: v1
      kind: Config
      clusters:
      - name: kubernetes
        cluster:
          certificate-authority-data: {{ jenkins_ca_b64 }}
          server: https://{{ master_private_ip }}:6443
      users:
      - name: jenkins
        user:
          token: "{{ jenkins_token }}"
      contexts:
      - name: jenkins@kubernetes
        context: { cluster: kubernetes, user: jenkins }
      current-context: jenkins@kubernetes
  delegate_to: localhost
  run_once: true
  become: false
  when: "'master-node' in group_names"

- name: Show path of the kube-config
  debug:
    msg: |
      -------------------------------------------------------------
      Saved kubeconfig to:  {{ playbook_dir }}/jenkins-kubeconfig.yaml

      In Jenkins → Manage → Clouds → Kubernetes:
        • Kubernetes URL : https://{{ master_private_ip }}:6443
        • Credentials    : upload that kube-config
      -------------------------------------------------------------
  run_once: true

